{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPkw1cXvzSsajh49duXhwjE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipetimoteo/machinelearnin/blob/main/Trabalho_Final_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "74ZuYcT5ZA_F",
        "outputId": "ecdf15e2-cc15-4ea5-de9e-212c9a5e4236"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5ee9305b2456>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m## Etapa 1: Análise preliminar de dados-------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Carregar os dados usando o Pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://github.com/felipetimoteo/machinelearnin/blob/ea7f73e0bedad8a5199c9a4bd4ddaddd265afa57/airfoil_self_noise.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Frequencia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AnguloAtaque'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ComprimentoCorda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VelocidadeFluxo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Espessura'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NivelPressao'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#1. Frequência, em Hertz.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 1487, saw 6\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "## Etapa 1: Análise preliminar de dados-------------------------------------------------\n",
        "# Carregar os dados usando o Pandas\n",
        "data = pd.read_csv('https://github.com/felipetimoteo/machinelearnin/blob/ea7f73e0bedad8a5199c9a4bd4ddaddd265afa57/airfoil_self_noise.dat', sep='\\t', header=None)\n",
        "data.columns = ['Frequencia', 'AnguloAtaque', 'ComprimentoCorda', 'VelocidadeFluxo', 'Espessura', 'NivelPressao']\n",
        "#1. Frequência, em Hertz.\n",
        "#2. Ângulo de ataque, em graus\n",
        "#3. Comprimento da corda, em metros\n",
        "#4. Velocidade de fluxo livre, em metros por segundo\n",
        "#5. Espessura do deslocamento do lado de sucção, em metros\n",
        "#A única saída é: 6. Nível de pressão sonora escalado, em decibéis. \n",
        "\n",
        "\n",
        "# Visualizar os primeiros registros\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Análises preliminares Preliminares-------------------------------------------------------------------\n",
        "# Scatter plots\n",
        "# data = data.iloc[:10, :] #Desmarcar esta linha se quiser ver apenas alguns dados.\n",
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
        "for i, column in enumerate(data.columns):\n",
        "    ax = axes[i // 3, i % 3]  # Determinar a posição do sub-plot na matriz de sub-plots\n",
        "    ax.scatter(data[column], data['NivelPressao'])  # Scatter plot com a coluna atual no eixo x e a coluna de saída no eixo y\n",
        "    ax.set_xlabel(column)\n",
        "    ax.set_ylabel('NivelPressao')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Plotar boxplots separadamente em figuras individuais\n",
        "for column in data.columns:\n",
        "    plt.figure()\n",
        "    plt.boxplot(data[column])\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Valores')\n",
        "\n",
        "plt.show() #Desmarque para ver os gráficos preliminares.\n"
      ],
      "metadata": {
        "id": "IOsXyknkZM1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 2: Treinamento da rede neural\n",
        "# Separar os dados de entrada (X) e saída (y)\n",
        "X = data.iloc[:, :-1] # Todas as colunas com exceção da última\n",
        "y = data.iloc[:, -1]  # Apenas a última coluna\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Criar e treinar o modelo de rede neural\n",
        "model = MLPRegressor(hidden_layer_sizes=(10,), activation='logistic', solver='adam', alpha=0.0001, random_state=42)\n",
        "#um modelo de regressão é criado usando MLPRegressor do scikit-learn.\n",
        "#A arquitetura da rede é definida com uma camada interna contendo 10 neurônios e\n",
        "#função de ativação logística.\n",
        "#Outras opções de hiperparâmetros podem ser ajustadas conforme necessário.\n",
        "#hidden_layer_sizes=(10,): Esse parâmetro define a arquitetura da rede neural, especificando o número de neurônios em cada camada oculta. Neste caso, temos uma única camada oculta com 10 neurônios. A escolha do número de neurônios na camada oculta é um aspecto importante a ser analisado, e você pode ajustá-lo para encontrar a melhor configuração para o seu problema.\n",
        "#activation='logistic': Esse parâmetro define a função de ativação utilizada nos neurônios da rede. Neste caso, foi escolhida a função logística, também conhecida como função sigmoide. A função sigmoide é uma função não linear com valores limitados entre 0 e 1, e é comumente utilizada em problemas de regressão. Você pode explorar outras funções de ativação disponíveis, como 'relu', 'tanh', entre outras, e analisar como elas afetam o desempenho do modelo.\n",
        "#random_state=42: Esse parâmetro define a semente para a inicialização dos pesos da rede neural. Ao definir um valor fixo para random_state, você garante que os resultados do modelo sejam reproduzíveis, ou seja, ao executar o código várias vezes, você obterá os mesmos resultados. Você pode alterar esse valor ou removê-lo para ter diferentes inicializações aleatórias.\n",
        "#A função de ativação escolhida, logistic, é uma função não linear que introduz não linearidades nas camadas ocultas da rede neural. Isso permite que o modelo aprenda relações não lineares nos dados, o que pode ser importante para problemas mais complexos. Você pode testar diferentes funções de ativação para encontrar a mais adequada ao seu conjunto de dados e problema em particular.\n",
        "\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prever os valores para o conjunto de teste\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "i-4a_3FhZSgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular o RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE:\", rmse)\n",
        "\n",
        "# Calcular o R²\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R²:\", r2)\n",
        "\n",
        "# Converter os valores previstos em classes discretas\n",
        "y_pred_classes = [1 if val > 0.5 else 0 for val in y_pred]\n",
        "\n",
        "# Construir a matriz de confusão\n",
        "confusion = confusion_matrix(y_test, y_pred_classes)\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(confusion)\n",
        "\n",
        "# Calcular a precisão e acurácia\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(\"Acurácia:\", accuracy)\n",
        "\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Erro quadrático médio (MSE):', mse)\n",
        "\n",
        "# Etapa 3: Análise dos parâmetros do algoritmo de treinamento\n",
        "# Você pode ajustar os parâmetros como tamanho do batch, valor do parâmetro de regularização (alpha), taxa de aprendizagem (learning_rate), etc."
      ],
      "metadata": {
        "id": "bxS-kYUgZdZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}